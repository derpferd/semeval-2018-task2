Author: Sai Cheedella.

This file contains info and references about all the 3rd party tools and scripts used for the project by Team Hopper.

File: scorer_semeval18.py

The scorer for our task(Multi Lingual Emoji Prediction) is a 3rd party code provided by the task organizers.

This script is used to evalute our classification model. It takes system output files and gold files as input and prints out the result.
The Result of scorer is Precision, Recall, Micro F-score and Macro F-score. Macro F score is used for official means of evaluation.
 

******** Tools installed from Requirements.txt**********

Four additonal tools are required to run the project script on your system. The tools are listed in the file named requirements.txt.

These description and source of the tools is as follows:

Natural Language ToolKit (NLTK): NLTK is an open source tool developed by University of Pennsylvania used for writing NLP programs in python.

For our project, NLTK packages are used in Naive Bayes Model(check model_naive_bayes_baselines.py). 
We import packages like TweetTokenizer, FreqDist and SklearnClassifier.(Check README in hopper folder for tokenization and  TFID transform).

Scikit Learn: It is a module for implementing machine learning algorithms in Python. It can be used for both supervised and unsupervised learning.

Scikit learn is used in Naive bayes model to import and implement Bernoulli Naive Bayes algorithm. (Check readme for more details of bernoulli classifier) 

SciPy: Scipy is a open source software used for implementing mathematical algorithms and functions in Python.

Keras: Keras is a Python library used to implement deep learning algorithms. It can be implemented on a backend software like "tensorflow" and is very easy to use with python.

Tensorflow: Tensor flow is a python API used for numerical computation using data flow graphs. Originally developed by google brain team, tensorflow makes it easier to deploy
the self learning features for NLP into applications.

Normalise: It is a Python module developed by University of cambridge , which is used to normalise text data.
Non Standard Words(Out of Vocabulary words) are detected, classified and expanded. (Check readme in Normalization folder for more details)


References:

http://www.nltk.org/index.html 

https://docs.scipy.org/doc/scipy/reference/tutorial/general.html

https://pypi.python.org/pypi/scikit-learn/0.19.0

https://keras.io/

https://www.tensorflow.org/

A Text Normalisation System for Non-Standard English Words
